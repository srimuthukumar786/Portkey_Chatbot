# Django LLM Analytics Project

This project integrates multiple LLM models using Portkey.ai and provides analytics dashboards for usage, cost, tokens, latency, and errors.

## Features
- Chat with multiple LLM models
- Tracks requests, tokens, latency, and cost
- Analytics dashboard with charts
- Model-wise and provider-wise usage stats

## Setup
1. Clone the repo
2. Create a virtual environment
3. Install dependencies:
   ```bash
   pip install -r requirements.txt
4.Signin in portkey.ai
5.Integrate LLM model with API_Key
6.Copy that API_Key and paste it in settings.py
7.Run the project